{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=pd.read_csv(r'C:\\Users\\49653\\Desktop\\yx\\data\\newdata.csv',encoding='utf-8')\n",
    "target=np.array(a['label'])\n",
    "data=np.array(a.drop(['label'],axis=1))\n",
    "X=data\n",
    "Y=target\n",
    "X_train,X_test,y_train,y_test= train_test_split(data,target,test_size=0.1,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AdaBoost():\n",
    "    clf = AdaBoostClassifier(n_estimators=100)  ##AdaBoost弱分类器\n",
    "    clf.fit(X_train,y_train)\n",
    "    yad_predict=clf.predict(X_test)\n",
    "    scores = cross_val_score(clf, X_train,y_train,cv=5)\n",
    "    print(\"模型拟合度为:\",scores)\n",
    "    print(classification_report(y_test,yad_predict))\n",
    "    plt.plot(yad_predict, label='pre')\n",
    "    plt.plot(y_test, label='true')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "def NBG():  ##朴素贝叶斯\n",
    "    clf= GaussianNB()\n",
    "    clf.fit(X_train,y_train)\n",
    "    ynbg_predict=clf.predict(X_test)\n",
    "    plt.plot(ynbg_predict, label='pre')\n",
    "    plt.plot(y_test, label='true')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    scores=clf.score(X_test,y_test)\n",
    "    print(\"模型拟合度为:\",scores)\n",
    "    print(classification_report(y_test,ynbg_predict)) \n",
    "def NBM():  ##朴素贝叶斯\n",
    "    clf=MultinomialNB()\n",
    "    clf.fit(X_train,y_train)\n",
    "    ynbm_predict=clf.predict(X_test)\n",
    "    plt.plot(ynbm_predict, label='pre')\n",
    "    plt.plot(y_test, label='true')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    scores=clf.score(X_test,y_test)\n",
    "    print(\"模型拟合度为:\",scores)\n",
    "    print(classification_report(y_test,ynbm_predict))\n",
    "def desic():\n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    ydesic_predict=clf.predict(X_test)\n",
    "    plt.plot(ydesic_predict, label='pre')\n",
    "    plt.plot(y_test, label='true')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    scores=clf.score(X_test,y_test)\n",
    "    print(\"模型拟合度为:\",scores)\n",
    "    print(classification_report(y_test,ydesic_predict)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "StreamlitAPIException",
     "evalue": "Radio Value has invalid type: str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStreamlitAPIException\u001b[0m                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-5a43e3508213>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0man\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mradio\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'AdaBoost'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'NBG'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'NBM'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'desic'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"AdaBoost\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"NBG\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"NBM\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"desic\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0man\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m\"AdaBoost\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAdaBoost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0man\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'NBG'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\A\\lib\\site-packages\\streamlit\\elements\\radio.py\u001b[0m in \u001b[0;36mradio\u001b[1;34m(self, label, options, index, format_func, key, help, on_change, args, kwargs)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m             raise StreamlitAPIException(\n\u001b[0m\u001b[0;32m    101\u001b[0m                 \u001b[1;34m\"Radio Value has invalid type: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m             )\n",
      "\u001b[1;31mStreamlitAPIException\u001b[0m: Radio Value has invalid type: str"
     ]
    }
   ],
   "source": [
    "an=st.radio('AdaBoost','NBG','NBM','desic',(\"AdaBoost\",\"NBG\",\"NBM\",\"desic\"))\n",
    "try:\n",
    "    if an==\"AdaBoost\":\n",
    "        st.info(AdaBoost())\n",
    "    elif an=='NBG':\n",
    "        st.info(NBG())\n",
    "    elif an=='NBM':\n",
    "        st.info(NBM())\n",
    "    elif an=='desic':\n",
    "        st.info(desic())\n",
    "except:\n",
    "    print(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils as utils\n",
    "import sys\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  ##因为我的GPU在第0个，所以特此标记\n",
    "torch.cuda.set_device(0)\n",
    "# 读取数据：\n",
    "train_data = pd.read_csv('train.csv',encoding='utf-8')\n",
    "test_data = pd.read_csv('test.csv',encoding='utf-8')\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "# 连接训练数据与测试数据\n",
    "all_features = pd.concat((train_data.iloc[:, 1:-1], test_data.iloc[:, 1:]))\n",
    "print(all_features.head(5))\n",
    "\n",
    "# 数据预处理：\n",
    "# 选泽合适索引：\n",
    "numeric_features = all_features.dtypes[all_features.dtypes != 'object'].index\n",
    "# 标准化：\n",
    "all_features[numeric_features] = all_features[numeric_features].apply(lambda x: (x - x.mean()) / (x.std()))\n",
    "# 缺失值补充：\n",
    "all_features[numeric_features] = all_features[numeric_features].fillna(0)\n",
    "\n",
    "# 离散数据转换成指示特征：\n",
    "# pd.get_dummies(data,prefix,columns,dummy_na)\n",
    "# prefix:转换后的前缀\n",
    "# columns:需要转换的列名\n",
    "# dummy_na:是否增加一列表示空缺值\n",
    "all_features = pd.get_dummies(all_features, dummy_na=True)\n",
    "print(all_features)\n",
    "# 通过values得到Numpy的数据，并转换成Tensor\n",
    "n_train = train_data.shape[0]  # 样本个数\n",
    "train_features = torch.tensor(all_features[:n_train].values, dtype=torch.float)  # 前n_train行\n",
    "test_features = torch.tensor(all_features[n_train:].values, dtype=torch.float)  # n_train行后\n",
    "train_labels = torch.tensor(train_data.label.values, dtype=torch.float).view(-1, 1)  # 标签列\n",
    "# 训练模型\n",
    "\n",
    "# 损失函数：MSE（均方差）\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "\n",
    "# 神经网络：\n",
    "def get_net(feature_num):\n",
    "    net = nn.Linear(feature_num, 1)\n",
    "\n",
    "    # 初始化模型参数：\n",
    "    # parameters()返回一个迭代器，每次生成的是tensor类型的数据：\n",
    "    for param in net.parameters():\n",
    "        nn.init.normal_(param, mean=0, std=0.01)\n",
    "\n",
    "    return net\n",
    "\n",
    "\n",
    "# 对数均方根误差的实现：\n",
    "def log_rmse(net, features, labels):\n",
    "    with torch.no_grad():\n",
    "        # 小于1的数设为1，取对数稳定\n",
    "        clipped_preds = torch.max(net(features), torch.tensor(1.0))\n",
    "        rmse = torch.sqrt(2 * loss(clipped_preds.float().log(), labels.float().log()).mean())\n",
    "    return rmse.item()  # item():得到该值\n",
    "\n",
    "\n",
    "# 训练数据\n",
    "def train(net, train_features, train_labels, test_features, test_labels,\n",
    "          num_epochs, learning_rate, weight_decay, batch_size):\n",
    "    train_ls, test_ls = [], []  # 损失\n",
    "    dataset = utils.data.TensorDataset(train_features, train_labels)\n",
    "    train_iter = utils.data.DataLoader(dataset, batch_size, shuffle=True)\n",
    "    # 优化器：Adam\n",
    "    optimizer = optim.Adam(params=net.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    net = net.float()\n",
    "    for epoch in range(num_epochs):\n",
    "        for x, y in train_iter:\n",
    "            # 正向传播：\n",
    "            output = net(x.float())\n",
    "            # 计算损失：\n",
    "            l = loss(output, y.float())\n",
    "            # 梯度归零\n",
    "            optimizer.zero_grad()\n",
    "            # 反向传播\n",
    "            l.backward()\n",
    "            # 优化参数\n",
    "            optimizer.step()\n",
    "\n",
    "        train_ls.append(log_rmse(net, train_features, train_labels))  # 训练集\n",
    "        if test_labels is not None:\n",
    "            test_ls.append(log_rmse(net, test_features, test_labels))  # 测试集\n",
    "\n",
    "    return train_ls, test_ls\n",
    "\n",
    "\n",
    "# K折交叉验证\n",
    "def get_k_fold_data(k, i, x, y):\n",
    "    # 返回第i折交叉验证需要的训练（x_train）和测试数据（x_test）\n",
    "    assert k > 1\n",
    "    fold_size = x.shape[0] // k\n",
    "    x_train, y_train = None, None\n",
    "    for j in range(k):\n",
    "        idx = slice(j * fold_size, (j + 1) * fold_size)  # 切片函数\n",
    "        x_part, y_part = x[idx, :], y[idx]\n",
    "        if j == i:  # 恰好i==j，直接载入测试集\n",
    "            x_test, y_test = x_part, y_part\n",
    "        elif x_train is None:  # 载入训练集\n",
    "            x_train, y_train = x_part, y_part\n",
    "        else:  # 将各个训练集相加\n",
    "            x_train = torch.cat((x_train, x_part), dim=0)\n",
    "            y_train = torch.cat((y_train, y_part), dim=0)\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "\n",
    "def use_svg_display():\n",
    "    # 用矢量图表示：\n",
    "    display.set_matplotlib_formats('svg')\n",
    "\n",
    "\n",
    "def set_figsize(figsize=(3.5, 2.5)):\n",
    "    use_svg_display()\n",
    "    # 设置图像尺寸\n",
    "    plt.rcParams['figure.figsize'] = figsize\n",
    "\n",
    "\n",
    "def semilogy(x_vals, y_vals, x_label, y_label, x2_vals=None, y2_vals=None,\n",
    "             legend=None, figsize=(3.5, 2.5)):\n",
    "    set_figsize(figsize)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.semilogy(x_vals, y_vals)  # semilogy:半对数函数\n",
    "    if x2_vals and y2_vals:\n",
    "        plt.semilogy(x2_vals, y2_vals, linestyle=':')\n",
    "        plt.legend(legend)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def k_fold(k, x_train, y_train, num_epochs, learning_rate, weight_decay, batch_size):\n",
    "    train_l_sum, valid_l_sum = 0, 0\n",
    "    for i in range(k):\n",
    "        data = get_k_fold_data(k, i, x_train, y_train)\n",
    "        net = get_net(x_train.shape[1])\n",
    "        train_ls, valid_ls = train(net, *data, num_epochs, learning_rate, weight_decay, batch_size)\n",
    "        train_l_sum += train_ls[-1]\n",
    "        valid_l_sum += valid_ls[-1]\n",
    "        if i == 0:\n",
    "            semilogy(range(1, num_epochs + 1), train_ls, 'epochs', 'rmse',\n",
    "                     range(1, num_epochs + 1), valid_ls, ['train', 'valid'])\n",
    "        print('fold %d, train rmse %f, valid rmse %f' % (i, train_ls[-1], valid_ls[-1]))\n",
    "    return train_l_sum / k, valid_l_sum / k  # 平均损失\n",
    "\n",
    "\n",
    "k, num_epochs, lr, weight_decay, batch_size = 10, 100, 5, 1.5, 256\n",
    "train_l, valid_l = k_fold(k, train_features, train_labels, num_epochs, lr, weight_decay, batch_size)\n",
    "print('%d-fold validation: avg train rmse %f,avg valid rmse %f' % (k, train_l, valid_l))\n",
    "\n",
    "\n",
    "def train_and_pred(train_features, test_features, train_labels, test_data,\n",
    "                   num_epochs, learning_rate, weight_decay, batch_size):\n",
    "    net = get_net(train_features.shape[1])\n",
    "    train_ls, _ = train(net, train_features, train_labels, None, None, num_epochs,\n",
    "                        learning_rate, weight_decay, batch_size)\n",
    "    semilogy(range(1, num_epochs + 1), train_ls, 'epochs', 'rmse')\n",
    "    print('train rmse %f' % train_ls[-1])\n",
    "    preds = net(test_features).detach().numpy()  ##神经网络对其进行预测\n",
    "\n",
    "    test_data['label'] = pd.Series(preds.reshape(1, -1)[0])\n",
    "    submission = pd.concat([test_data['length'], test_data['label']], axis=1)\n",
    "    submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "\n",
    "train_and_pred(train_features, test_features, train_labels, test_data,\n",
    "               num_epochs, lr, weight_decay, batch_size)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
